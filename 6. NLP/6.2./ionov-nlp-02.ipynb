{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.3'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этой командой открывается диалоговое окно для скачивания корпусов и моделей для NLTK.\n",
    "Для следующих команд нужны пакеты `Punkt Tokenizer Tagger`, `Averaged Perceptron Tagger`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируем предложение на английском:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = \"\"\"Trump was born in the New York City borough of Queens and earned an economics degree from the Wharton School of the University of Pennsylvania.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_rus = \"\"\"\n",
    "Во втором туре выборов президента Российской академии наук победил академик Александр Сергеев, \n",
    "сообщил результаты подсчета голосов председатель счетной комиссии Юрий Балега.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trump',\n",
       " 'was',\n",
       " 'born',\n",
       " 'in',\n",
       " 'the',\n",
       " 'New',\n",
       " 'York',\n",
       " 'City',\n",
       " 'borough',\n",
       " 'of',\n",
       " 'Queens',\n",
       " 'and',\n",
       " 'earned',\n",
       " 'an',\n",
       " 'economics',\n",
       " 'degree',\n",
       " 'from',\n",
       " 'the',\n",
       " 'Wharton',\n",
       " 'School',\n",
       " 'of',\n",
       " 'the',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Pennsylvania',\n",
       " '.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя список токенов, можно получить частеречную разметку\n",
    "(NB: для парсинга более, чем одного предложения нужно использовать `pos_tag_sents()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagged = nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Trump', 'NNP'),\n",
       " ('was', 'VBD'),\n",
       " ('born', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('New', 'NNP'),\n",
       " ('York', 'NNP'),\n",
       " ('City', 'NNP'),\n",
       " ('borough', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Queens', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('earned', 'VBD'),\n",
       " ('an', 'DT'),\n",
       " ('economics', 'NNS'),\n",
       " ('degree', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Wharton', 'NNP'),\n",
       " ('School', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('University', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Pennsylvania', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно сделать то же самое для русского. Описание тегсета можно найти здесь: http://www.ruscorpora.ru/corpora-morph.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Во', 'PR'),\n",
       " ('втором', 'ANUM=m'),\n",
       " ('туре', 'S'),\n",
       " ('выборов', 'S'),\n",
       " ('президента', 'S'),\n",
       " ('Российской', 'A=f'),\n",
       " ('академии', 'S'),\n",
       " ('наук', 'S'),\n",
       " ('победил', 'V'),\n",
       " ('академик', 'S'),\n",
       " ('Александр', 'S'),\n",
       " ('Сергеев', 'S'),\n",
       " (',', 'NONLEX'),\n",
       " ('сообщил', 'V'),\n",
       " ('результаты', 'S'),\n",
       " ('подсчета', 'S'),\n",
       " ('голосов', 'S'),\n",
       " ('председатель', 'S'),\n",
       " ('счетной', 'A=f'),\n",
       " ('комиссии', 'S'),\n",
       " ('Юрий', 'S'),\n",
       " ('Балега', 'S'),\n",
       " ('.', 'NONLEX')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(sentence_rus), lang='rus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно было заметить, что процесс был не очень быстрый. Часть времени тратится на инициализацию тэггера и загрузку модели. Можно это сделать отдельно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trump',\n",
       " 'was',\n",
       " 'born',\n",
       " 'in',\n",
       " 'the',\n",
       " 'New',\n",
       " 'York',\n",
       " 'City',\n",
       " 'borough',\n",
       " 'of',\n",
       " 'Queens',\n",
       " 'and',\n",
       " 'earned',\n",
       " 'an',\n",
       " 'economics',\n",
       " 'degree',\n",
       " 'from',\n",
       " 'the',\n",
       " 'Wharton',\n",
       " 'School',\n",
       " 'of',\n",
       " 'the',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Pennsylvania']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.RegexpTokenizer('\\w+')\n",
    "words = tokenizer.tokenize(sentence)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trump',\n",
       " 'was',\n",
       " 'born',\n",
       " 'in',\n",
       " 'the',\n",
       " 'New',\n",
       " 'York',\n",
       " 'City',\n",
       " 'borough',\n",
       " 'of',\n",
       " 'Queens',\n",
       " 'and',\n",
       " 'earned',\n",
       " 'an',\n",
       " 'economics',\n",
       " 'degree',\n",
       " 'from',\n",
       " 'the',\n",
       " 'Wharton',\n",
       " 'School',\n",
       " 'of',\n",
       " 'the',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Pennsylvania',\n",
       " '.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "words = tokenizer.tokenize(sentence)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Trump', 'NNP'),\n",
       " ('was', 'VBD'),\n",
       " ('born', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('New', 'NNP'),\n",
       " ('York', 'NNP'),\n",
       " ('City', 'NNP'),\n",
       " ('borough', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Queens', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('earned', 'VBD'),\n",
       " ('an', 'DT'),\n",
       " ('economics', 'NNS'),\n",
       " ('degree', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Wharton', 'NNP'),\n",
       " ('School', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('University', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Pennsylvania', 'NNP')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = nltk.tag.PerceptronTagger()\n",
    "tagger.tag(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для русского языка нужно найти модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Во', 'PR'),\n",
       " ('втором', 'ANUM=m'),\n",
       " ('туре', 'S'),\n",
       " ('выборов', 'S'),\n",
       " ('президента', 'S'),\n",
       " ('Российской', 'A=f'),\n",
       " ('академии', 'S'),\n",
       " ('наук', 'S'),\n",
       " ('победил', 'V'),\n",
       " ('академик', 'S'),\n",
       " ('Александр', 'S'),\n",
       " ('Сергеев', 'S'),\n",
       " ('сообщил', 'V'),\n",
       " ('результаты', 'S'),\n",
       " ('подсчета', 'S'),\n",
       " ('голосов', 'S'),\n",
       " ('председатель', 'S'),\n",
       " ('счетной', 'A=f'),\n",
       " ('комиссии', 'S'),\n",
       " ('Юрий', 'S'),\n",
       " ('Балега', 'S')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = nltk.tag.PerceptronTagger(load=False)\n",
    "tagger.load(nltk.data.find('taggers/averaged_perceptron_tagger_ru/averaged_perceptron_tagger_ru.pickle'))\n",
    "tagger.tag(tokenizer.tokenize(sentence_rus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MyStem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymystem3 in /Users/max/anaconda/lib/python2.7/site-packages\n",
      "Requirement already satisfied: requests in /Users/max/anaconda/lib/python2.7/site-packages (from pymystem3)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /Users/max/anaconda/lib/python2.7/site-packages (from requests->pymystem3)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /Users/max/anaconda/lib/python2.7/site-packages (from requests->pymystem3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/max/anaconda/lib/python2.7/site-packages (from requests->pymystem3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/max/anaconda/lib/python2.7/site-packages (from requests->pymystem3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymystem3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так инициализируется объект pymystem3. При необходимости скачивается сам майстем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = pymystem3.Mystem(disambiguation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = m.analyze('Глокая куздра штеко будланула бокра и кудрячит бокренка')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S,муж,неод=род,ед\n",
      "S,ед,жен,неод=им\n",
      "ADV=\n",
      "S,муж,од=(вин,ед|род,ед)\n",
      "S,ед,жен,неод=им\n",
      "CONJ=\n",
      "V,несов,пе=непрош,ед,изъяв,3-л\n",
      "S,муж,неод=род,ед\n"
     ]
    }
   ],
   "source": [
    "for w in res:\n",
    "    if 'analysis' not in w:\n",
    "        continue\n",
    "    for item in w['analysis']:\n",
    "        print (item['gr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ученый\n",
      " \n",
      "в\n",
      " \n",
      "течение\n",
      " \n",
      "год\n",
      " \n",
      "готовиться\n",
      " \n",
      "к\n",
      " \n",
      "встреча\n",
      " \n",
      "комета\n",
      " \n",
      "сайдинг\n",
      "-\n",
      "спринг\n",
      " \n",
      "с\n",
      " \n",
      "марс\n",
      ", \n",
      "когда\n",
      " \n",
      "мощный\n",
      " \n",
      "вспышка\n",
      " \n",
      "на\n",
      " \n",
      "солнце\n",
      " \n",
      "разрушать\n",
      " \n",
      "весь\n",
      " \n",
      "план\n",
      " \n",
      "специалист\n",
      ". \n",
      "в\n",
      " \n",
      "октябрь\n",
      " \n",
      "2014\n",
      " \n",
      "год\n",
      " \n",
      "комета\n",
      " \n",
      "сайдинг\n",
      "-\n",
      "спринг\n",
      " \n",
      "приближаться\n",
      " \n",
      "к\n",
      " \n",
      "красный\n",
      " \n",
      "планета\n",
      " \n",
      "на\n",
      " \n",
      "близкий\n",
      " \n",
      "расстояние\n",
      ", \n",
      "о\n",
      " \n",
      "что\n",
      " \n",
      "становиться\n",
      " \n",
      "известно\n",
      " \n",
      "из\n",
      " \n",
      "материал\n",
      " \n",
      "исследование\n",
      " \n",
      "астроном\n",
      ".\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in m.lemmatize('Ученые в течение года готовились к встрече кометы Сайдинг-Спринг с Марсом, когда мощная вспышка на Солнце разрушила все планы специалистов. В октябре 2014 года комета Сайдинг-Спринг приблизилась к Красной планете на близкое расстояние, о чем стало известно из материалов исследования астрономов.'):\n",
    "    print (item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SyntaxNet\n",
    "Если установлен и запущен SyntaxNet из докер-контейнера, можно к нему обращаться через сокеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "host = '127.0.0.1'\n",
    "port = 8111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_all_from_socket(sock):\n",
    "    buf = str()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            data = sock.recv(51200)\n",
    "            if data:\n",
    "                buf += data.decode('utf-8')\n",
    "            else:\n",
    "                break\n",
    "    except socket.error as err:\n",
    "        print ('Err: Socket error: {}'.format(err))\n",
    "\n",
    "    return buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "sock.connect((host, port))\n",
    "sock.send((sentence_rus + '\\n\\n').encode('utf8'))\n",
    "raw_output = read_all_from_socket(sock)\n",
    "sock.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tВо\t_\tINTJ\tUH\tfPOS=INTJ++UH\t4\tdiscourse\t_\t_\n",
      "2\tвтором\t_\tX\tLS\tfPOS=INTJ++UH\t4\tdiscourse\t_\t_\n",
      "3\tтуре\t_\tX\tLS\tfPOS=INTJ++UH\t4\tnsubj\t_\t_\n",
      "4\tвыборов\t_\tVERB\tVBZ\tfPOS=INTJ++UH\t0\tROOT\t_\t_\n",
      "5\tпрезидента\t_\tNOUN\tNN\tfPOS=INTJ++UH\t4\tparataxis\t_\t_\n",
      "6\tРоссийской\t_\tNOUN\tNN\tfPOS=INTJ++UH\t5\tdobj\t_\t_\n",
      "7\tакадемии\t_\tNOUN\tNN\tfPOS=INTJ++UH\t6\tacl\t_\t_\n",
      "8\tнаук\t_\tNOUN\tNN\tfPOS=INTJ++UH\t12\tcompound\t_\t_\n",
      "9\tпобедил\t_\tNOUN\tNN\tfPOS=INTJ++UH\t10\tcompound\t_\t_\n",
      "10\tакадемик\t_\tNOUN\tNN\tfPOS=INTJ++UH\t12\tcompound\t_\t_\n",
      "11\tАлександр\t_\tNOUN\tNN\tfPOS=INTJ++UH\t12\tcompound\t_\t_\n",
      "12\tСергеев,\t_\tNOUN\tNN\tNumType=Card|fPOS=NUM++CD\t7\tdobj\t_\t_\n",
      "\n",
      "1\tсообщил\t_\tINTJ\tUH\tfPOS=INTJ++UH\t3\tdiscourse\t_\t_\n",
      "2\tрезультаты\t_\tPRON\tPRP\tfPOS=INTJ++UH\t3\tnsubj\t_\t_\n",
      "3\tподсчета\t_\tVERB\tVBP\tfPOS=INTJ++UH\t0\tROOT\t_\t_\n",
      "4\tголосов\t_\tNOUN\tNN\tfPOS=INTJ++UH\t7\tcompound\t_\t_\n",
      "5\tпредседатель\t_\tNOUN\tNN\tfPOS=INTJ++UH\t7\tcompound\t_\t_\n",
      "6\tсчетной\t_\tNOUN\tNN\tfPOS=INTJ++UH\t7\tcompound\t_\t_\n",
      "7\tкомиссии\t_\tNOUN\tNN\tfPOS=INTJ++UH\t3\tparataxis\t_\t_\n",
      "8\tЮрий\t_\tNOUN\tNN\tfPOS=INTJ++UH\t7\tdiscourse\t_\t_\n",
      "9\tБалега.\t_\tPUNCT\t.\tfPOS=PUNCT++.\t7\tpunct\t_\t_\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(raw_output)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
